{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "highway = glob.glob(os.path.join(\"./data/baseline/highway/input\", \"*.jpg\"))\n",
        "office = glob.glob(os.path.join(\"./data/baseline/office/input\", \"*.jpg\"))\n",
        "pedestrians = glob.glob(os.path.join(\"./data/baseline/pedestrians/input\", \"*.jpg\"))\n",
        "PETS2006 = glob.glob(os.path.join(\"./data/baseline/PETS2006/input\", \"*.jpg\"))\n",
        "\n",
        "\n",
        "highway_ref = glob.glob(os.path.join(\"./data/baseline/highway/groundtruth\", \"*.png\"))\n",
        "office_ref = glob.glob(os.path.join(\"./data/baseline/office/groundtruth\", \"*.png\"))\n",
        "pedestrians_ref = glob.glob(os.path.join(\"./data/baseline/pedestrians/groundtruth\", \"*.png\"))\n",
        "PETS2006_ref = glob.glob(os.path.join(\"./data/baseline/PETS2006/groundtruth\", \"*.png\"))\n",
        "\n",
        "\n",
        "# small_test_office = glob.glob(os.path.join(\"./data/baseline/small_test_office/input\", \"*.jpg\"))\n",
        "# small_test_office_ref = glob.glob(os.path.join(\"./data/baseline/small_test_office/groundtruth\", \"*.png\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_background_substrated_image(image_path, background_image):\n",
        "  threshold = 40\n",
        "  image = (cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "\n",
        "  diff = numpy.abs(image - background_image) >= threshold\n",
        "\n",
        "  int_image = diff.astype(int)\n",
        "\n",
        "  # plt.imshow(~int_image,plt.get_cmap('binary'))\n",
        "  # plt.show()\n",
        "  return int_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def Mask_RCNN(dataset):\n",
        "  tensors = []\n",
        "  preprocess = transforms.Compose([transforms.ToTensor()])\n",
        "  THRESHOLD = 0.25\n",
        "  result = []\n",
        "\n",
        "  timestamp = time.time()\n",
        "  \n",
        "  for img_path in dataset:\n",
        "    img = io.imread(img_path)\n",
        "    tensors.append(preprocess(img))\n",
        "\n",
        "  print(f\"Loading images: {time.time() - timestamp}\")\n",
        "  timestamp = time.time()\n",
        "    \n",
        "  model = models.detection.maskrcnn_resnet50_fpn(weights='COCO_V1').eval()\n",
        "  predictions = model(tensors)\n",
        "\n",
        "  print(f\"Model: {time.time() - timestamp}\")\n",
        "  timestamp = time.time()\n",
        "\n",
        "  for prediction in predictions:\n",
        "    img_result = []\n",
        "    \n",
        "    for j, score in enumerate(prediction['scores']):\n",
        "        if score >= THRESHOLD:\n",
        "          \n",
        "          mask = prediction['masks'][j][0].detach().numpy()\n",
        "          if len(img_result) == 0:\n",
        "            img_result = numpy.array(mask)\n",
        "          else:\n",
        "            img_result = numpy.maximum(img_result, mask)\n",
        "\n",
        "    result.append(img_result)\n",
        "    \n",
        "  print(f\"Prediction: {time.time() - timestamp}\")\n",
        "\n",
        "  return result\n",
        "\n",
        "Mask_RCNN(highway[100:103])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substract_background(dataset, background_image_index):\n",
        "    background_image = (cv2.imread(dataset[background_image_index], cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "\n",
        "    result = []\n",
        "    for path in dataset:\n",
        "        result.append(generate_background_substrated_image(path, background_image))\n",
        "    \n",
        "    return result\n",
        "\n",
        "result = substract_background(office, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par modèle binaire locaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_LBP(query, database, longueurCodes, rayon, all):\n",
        "    lbp_db_descriptors = []\n",
        "    for path_db in database:\n",
        "        row_lbp, col_lbp = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "        lbp_hist_db, _ = numpy.histogram(desc_LBP(path_db, longueurCodes, rayon), bins = range(256))\n",
        "        lbp_hist_db = lbp_hist_db / (row_lbp * col_lbp)\n",
        "        lbp_db_descriptors.append(lbp_hist_db)\n",
        "\n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        lbp_query = desc_LBP(path_query, longueurCodes, rayon)\n",
        "\n",
        "        row_lbp, col_lbp = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "        lbp_hist_query, _ = numpy.histogram(lbp_query, bins = range(256))\n",
        "        lbp_hist_query = lbp_hist_query / (row_lbp * col_lbp)\n",
        "\n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        # path = path_query.split('\\\\')[1][:-4]\n",
        "        # result_path = f\"./results/LBP/R{rayon}-P{longueurCodes}\"\n",
        "\n",
        "        # os.makedirs(result_path, exist_ok=True)\n",
        "\n",
        "        # with open(f\"{result_path}/{path}.csv\", 'w+', newline='') as file:\n",
        "            # writer = csv.writer(file)\n",
        "            # field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "        for key in methods:\n",
        "            result[key] = []\n",
        "        \n",
        "        index = 0\n",
        "        for path_db in database:\n",
        "            lbp_hist_db = lbp_db_descriptors[index]\n",
        "\n",
        "            result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "            result[\"intersection\"].append((result_id, intersection(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"norms1\"].append((result_id, norms1(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"norms2\"].append((result_id, norms2(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"bhattacharyya\"].append((result_id, bhattacharyya(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            index += 1\n",
        "\n",
        "            # writer.writerow([path + f\" ({timeList[0]})\"] + methods)\n",
        "\n",
        "            # for f in range(1, len(field)):\n",
        "            #     writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()])\n",
        "        \n",
        "        # for key in result.keys():\n",
        "        #     if key not in all:\n",
        "        #         all[key] = dict()\n",
        "        #     reverse = True if (key == \"intersection\") else False\n",
        "        #     data = [x[0] for x in sorted(result[key], key=lambda tp: tp[1], reverse=reverse)[:3]]\n",
        "        #     for d in data:\n",
        "        #         img_name = d.split(':')[0][:-6]\n",
        "        #         db_name = d.split(':')[1][:-2]\n",
        "        #         if \"strawberry\" in img_name:\n",
        "        #             if img_name not in all[key]:\n",
        "        #                 all[key][img_name] = dict()\n",
        "        #             if db_name not in all[key][img_name]:\n",
        "        #                 all[key][img_name][db_name] = 0\n",
        "        #             all[key][img_name][db_name] += 1\n",
        "        #         else:\n",
        "        #             if img_name not in all[key]:\n",
        "        #                 all[key][img_name] = (0, 0)\n",
        "        #             if img_name == db_name:\n",
        "        #                 all[key][img_name] = (all[key][img_name][0] + 1, all[key][img_name][1])\n",
        "        #             all[key][img_name] = (all[key][img_name][0], all[key][img_name][1] + 1)\n",
        "\n",
        "all = dict()\n",
        "\n",
        "timestamp = time.time()\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        classify_LBP(query, database, longueurCodes, rayon, all)\n",
        "\n",
        "print(f\"Time Normal: {time.time() - timestamp}\")\n",
        "\n",
        "timestamp = time.time()\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        classify_LBP(query_cropped, database_cropped, longueurCodes, rayon, all)\n",
        "print(f\"Time Cropped: {time.time() - timestamp}\")\n",
        "\n",
        "# print(all)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
