{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import urllib.request as request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "highway = glob.glob(os.path.join(\"./data/baseline/highway/input\", \"*.jpg\"))\n",
        "office = glob.glob(os.path.join(\"./data/baseline/office/input\", \"*.jpg\"))\n",
        "pedestrians = glob.glob(os.path.join(\"./data/baseline/pedestrians/input\", \"*.jpg\"))\n",
        "PETS2006 = glob.glob(os.path.join(\"./data/baseline/PETS2006/input\", \"*.jpg\"))\n",
        "\n",
        "highway_ref = glob.glob(os.path.join(\"./data/baseline/highway/groundtruth\", \"*.png\"))\n",
        "office_ref = glob.glob(os.path.join(\"./data/baseline/office/groundtruth\", \"*.png\"))\n",
        "pedestrians_ref = glob.glob(os.path.join(\"./data/baseline/pedestrians/groundtruth\", \"*.png\"))\n",
        "PETS2006_ref = glob.glob(os.path.join(\"./data/baseline/PETS2006/groundtruth\", \"*.png\"))\n",
        "\n",
        "\n",
        "# small_test_office = glob.glob(os.path.join(\"./data/baseline/small_test_office/input\", \"*.jpg\"))\n",
        "# small_test_office_ref = glob.glob(os.path.join(\"./data/baseline/small_test_office/groundtruth\", \"*.png\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_background_substrated_image(image_path, background_images, num):\n",
        "  threshold = 25\n",
        "  minDectections = 0.7 * len(background_images)\n",
        "\n",
        "  image = (cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "  diff_sum = []\n",
        "\n",
        "  for background_image in background_images:\n",
        "    diff = numpy.abs(image - background_image) >= threshold\n",
        "    if len(diff_sum) == 0:\n",
        "      diff_sum = diff.astype('int')\n",
        "    else:\n",
        "      diff_sum += diff.astype('int')\n",
        "\n",
        "  front_image = diff_sum >= minDectections\n",
        "\n",
        "  # if (num > 100 and num < 105) or (num > 250 and num < 255) or (num > 400 and num < 405) or (num > 550 and num < 555) or (num > 700 and num < 705) or (num > 850 and num < 855):\n",
        "  #   plt.imshow(~front_image,plt.get_cmap('binary'))\n",
        "  #   plt.show()\n",
        "  return front_image.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction with One Background Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_background_substrated_image_1(image_path, background_image, num):\n",
        "  threshold = 40\n",
        "\n",
        "  image = (cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "\n",
        "  diff = numpy.abs(image - background_image) >= threshold\n",
        "\n",
        "  index_to_print = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, 1500]\n",
        "  # if num in index_to_print:\n",
        "  #   plt.imshow(~diff,plt.get_cmap('binary'))\n",
        "  #   plt.show()\n",
        "  return diff.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "COCO_NAMES = ['background']\n",
        "label_names = request.urlopen('https://raw.githubusercontent.com/gabilodeau/INF6804/master/utils/coco-labels.txt')\n",
        "for label_name in label_names.readlines():\n",
        "  COCO_NAMES.append(label_name.strip().decode('UTF-8'))\n",
        "\n",
        "def Mask_RCNN(dataset):\n",
        "  tensors = []\n",
        "  preprocess = transforms.Compose([transforms.ToTensor()])\n",
        "  THRESHOLD = 0.30\n",
        "  result = []\n",
        "  shapes = []\n",
        "  \n",
        "  for img_path in dataset:\n",
        "    img = io.imread(img_path)\n",
        "    tensors.append(preprocess(img))\n",
        "    shapes.append(img.shape)\n",
        "    \n",
        "  model = models.detection.maskrcnn_resnet50_fpn(weights='DEFAULT').eval()\n",
        "  predictions = model(tensors)\n",
        "\n",
        "  for index in range(0, len(predictions)):\n",
        "    prediction = predictions[index]\n",
        "    img_result = numpy.zeros(shapes[index][:2])\n",
        "    \n",
        "    for j, score in enumerate(prediction['scores']):\n",
        "        if score >= THRESHOLD:\n",
        "          \n",
        "          mask = prediction['masks'][j][0].detach().numpy()\n",
        "          if len(img_result) == 0:\n",
        "            img_result = numpy.array(mask)\n",
        "          else:\n",
        "            img_result = numpy.maximum(img_result, mask)\n",
        "\n",
        "    result.append(img_result)\n",
        "\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substract_background(dataset, background_indices):\n",
        "    background_images = []\n",
        "    for index in background_indices:\n",
        "        background_images.append((cv2.imread(dataset[index], cv2.IMREAD_GRAYSCALE)).astype(float))\n",
        "\n",
        "    result = []\n",
        "    num = 0\n",
        "\n",
        "    for path in dataset:\n",
        "        print('Image #' + str(num))\n",
        "        result.append(generate_background_substrated_image(path, background_images, num))\n",
        "        num += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "substract_background(office, [x for x in range(len(office)) if x % 50 == 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction with One Background Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substract_background_1(dataset, background_indice):\n",
        "    \n",
        "    background_image = (cv2.imread(dataset[background_indice], cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "\n",
        "    result = []\n",
        "    num = 0\n",
        "\n",
        "    for path in dataset:\n",
        "        print('Image #' + str(num))\n",
        "        result.append(generate_background_substrated_image_1(path, background_image, num))\n",
        "        num += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "substract_background_1(office, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparaison des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_difference(dataset, dataset_ref, show_img = False):\n",
        "    result = []\n",
        "\n",
        "    video_SI =  substract_background(dataset, [x for x in range(len(dataset)) if x % 50 == 0])\n",
        "    video_BR =  substract_background_1(dataset, 0)\n",
        "\n",
        "    for img_index in range(0, len(dataset_ref)):\n",
        "        img_ref = numpy.array(cv2.imread(dataset_ref[img_index], cv2.IMREAD_GRAYSCALE).astype(float)) / 255\n",
        "        img_SI = video_SI[img_index]\n",
        "        img_BR = video_BR[img_index]\n",
        "\n",
        "        flatten = img_ref.flatten()\n",
        "        factor = (flatten[flatten != 0]).size\n",
        "        factor = 1 if (factor == 0) else factor\n",
        "        \n",
        "        result_SI = (1 - (norms1(img_SI, img_ref) / factor)) * 100\n",
        "        result_BR = (1 - (norms1(img_BR, img_ref) / factor)) * 100\n",
        "\n",
        "        if (show_img):\n",
        "            plt.imshow(img_ref); plt.axis('off'); plt.show()\n",
        "\n",
        "            plt.imshow(img_SI); plt.axis('off'); plt.show()\n",
        "            plt.imshow(numpy.abs(img_SI - img_ref)); plt.axis('off'); plt.show()\n",
        "\n",
        "            plt.imshow(img_BR); plt.axis('off'); plt.show()\n",
        "            plt.imshow(numpy.abs(img_BR - img_ref)); plt.axis('off'); plt.show()\n",
        "\n",
        "        print(f\"{img_index}: (SI:{result_SI}, BR:{result_BR})\")\n",
        "        result.append((result_SI, result_BR))\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [highway, office, pedestrians, PETS2006]\n",
        "data_ref = [highway_ref, office_ref, pedestrians_ref, PETS2006_ref]\n",
        "data_name = [\"highway\", \"office\", \"pedestrians\", \"PETS2006\"]\n",
        "data_background_indices = [[2, 76], [], [], []]\n",
        "\n",
        "for data_index in range(0, len(data)):\n",
        "    current_data = data[data_index]\n",
        "    current_data_ref = data_ref[data_index]\n",
        "\n",
        "    current_result = classify_difference(current_data, current_data_ref)\n",
        "\n",
        "    with open(f\"{data_name[data_index]}.csv\", 'w+', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"index\", \"SI\", \"BR\"])\n",
        "        \n",
        "        for i in range(0, len(current_result)):\n",
        "            writer.writerow([i, current_result[i][0], current_result[i][1]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
