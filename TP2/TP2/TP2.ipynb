{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "from skimage.feature import graycomatrix\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from skimage import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "highway = glob.glob(os.path.join(\"./data/baseline/highway/input\", \"*.jpg\"))\n",
        "office = glob.glob(os.path.join(\"./data/baseline/office/input\", \"*.jpg\"))\n",
        "pedestrians = glob.glob(os.path.join(\"./data/baseline/pedestrians/input\", \"*.jpg\"))\n",
        "PETS2006 = glob.glob(os.path.join(\"./data/baseline/PETS2006/input\", \"*.jpg\"))\n",
        "\n",
        "highway_ref = glob.glob(os.path.join(\"./data/baseline/highway/groundtruth\", \"*.png\"))\n",
        "office_ref = glob.glob(os.path.join(\"./data/baseline/office/groundtruth\", \"*.png\"))\n",
        "pedestrians_ref = glob.glob(os.path.join(\"./data/baseline/pedestrians/groundtruth\", \"*.png\"))\n",
        "PETS2006_ref = glob.glob(os.path.join(\"./data/baseline/PETS2006/groundtruth\", \"*.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def desc_cm_params(imagePath, distances = [1, 5, 10], angles = [0, numpy.pi / 2, numpy.pi, 3 * numpy.pi / 4]):\n",
        "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
        "    nb_channels = 3\n",
        "    nb_rows = len(image)\n",
        "    nb_columns = len(image[0])\n",
        "\n",
        "    three_channel_one_dimension_desc = []\n",
        "    \n",
        "    for channel in range(nb_channels):\n",
        "      one_channel_image = []\n",
        "      for row in range(nb_rows):\n",
        "        one_channel_image.append([])\n",
        "        for column in range(nb_columns):\n",
        "          one_channel_image[row].append(image[row][column][channel])\n",
        "      cm = graycomatrix(one_channel_image, distances, angles, normed=True)\n",
        "    \n",
        "      one_dimension_descriptors = []\n",
        "      for distance in range(len(cm[0][0])):\n",
        "        one_dimension_descriptors.append([])\n",
        "        for angle in range(len(cm[0][0][0])):\n",
        "            one_dimension_descriptors[distance].append([])\n",
        "            one_dim_desc = []\n",
        "            for row in range(len(cm)):\n",
        "                for col in range(len(cm[0])):\n",
        "                    one_dim_desc.append(cm[row][col][distance][angle])\n",
        "            one_dimension_descriptors[distance][angle].append(numpy.asarray(one_dim_desc, numpy.float32))\n",
        "      three_channel_one_dimension_desc.append(one_dimension_descriptors)\n",
        "\n",
        "    return three_channel_one_dimension_desc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 58\u001b[0m\n\u001b[0;32m     54\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img); plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m); plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43mMask_RCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhighway\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[15], line 44\u001b[0m, in \u001b[0;36mMask_RCNN\u001b[1;34m(database)\u001b[0m\n\u001b[0;32m     41\u001b[0m label\u001b[38;5;241m=\u001b[39mprediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][j]\n\u001b[0;32m     42\u001b[0m x1,y1,x2,y2 \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m][j]\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, y1, x2, y2)\n\u001b[0;32m     46\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maddWeighted(img, \u001b[38;5;241m1\u001b[39m, colored_mask, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     47\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(img, (x1, y1), (x2, y2), color\u001b[38;5;241m.\u001b[39mtolist(), \u001b[38;5;241m10\u001b[39m)\n",
            "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def Mask_RCNN(database):\n",
        "  tensors = []\n",
        "  preprocess = transforms.Compose([transforms.ToTensor()])\n",
        "  THRESHOLD = 0.75\n",
        "  \n",
        "  for img_path in [database[0]]:\n",
        "    img = io.imread(img_path)\n",
        "    tensors.append(preprocess(img))\n",
        "    \n",
        "  model = models.detection.maskrcnn_resnet50_fpn(weights='DEFAULT').eval()\n",
        "  predictions = model(tensors)\n",
        "\n",
        "  for prediction in predictions:\n",
        "    mask = prediction['masks'][0][0].detach().numpy()\n",
        "    break\n",
        "\n",
        "  for i, prediction in enumerate(predictions):\n",
        "    img = tensors[i].permute(1,2,0).mul(255).byte().numpy()\n",
        "\n",
        "    nb_objects=0\n",
        "    for j, score in enumerate(prediction['scores']):\n",
        "        if score >= THRESHOLD:\n",
        "          \n",
        "          mask = prediction['masks'][j][0].detach().numpy()\n",
        "\n",
        "          name_colors=list(mcolors.CSS4_COLORS.keys())\n",
        "          name_colors.remove('black')\n",
        "          rgb_colors=np.array([(np.array(mcolors.to_rgb(i))*255).astype(\"uint8\") for i in name_colors])\n",
        "          r = np.zeros_like(mask).astype(np.uint8)\n",
        "          g = np.zeros_like(mask).astype(np.uint8)\n",
        "          b = np.zeros_like(mask).astype(np.uint8)\n",
        "          color = rgb_colors[random.randrange(0,len(rgb_colors))]\n",
        "          r[mask > 0.5], g[mask > 0.5], b[mask > 0.5] = color\n",
        "          colored_mask = np.stack([r, g, b], axis=2)\n",
        "\n",
        "          label=prediction['labels'][j]\n",
        "          x1,y1,x2,y2 = prediction['boxes'][j]\n",
        "\n",
        "          print(x1[0], y1, x2, y2)\n",
        "\n",
        "          img = cv2.addWeighted(img, 1, colored_mask, 0.5, 0)\n",
        "          img = cv2.rectangle(img, (x1, y1), (x2, y2), color.tolist(), 10)\n",
        "          \n",
        "          nb_objects+=1\n",
        "\n",
        "    print('nbobjects (over threshold): ', nb_objects)\n",
        "\n",
        "    plt.figure(figsize = (10,10))\n",
        "    plt.imshow(img); plt.axis('off'); plt.show()\n",
        "\n",
        "  return\n",
        "\n",
        "Mask_RCNN(highway)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par matrice de co-occurrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_CM(query, database):\n",
        "    cm_db_descriptors = []\n",
        "    for path_db in database:\n",
        "        cm_db_descriptors.append(desc_cm_params(path_db))\n",
        "    \n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        cm_query_descriptors = desc_cm_params(path_query)\n",
        "    \n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        #path = path_query.split('\\\\')[1][:-4]\n",
        "        # with open(f\"./results/CM/{path}.csv\", 'w+', newline='') as file:\n",
        "        #     writer = csv.writer(file)\n",
        "        #     field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "        for key in methods:\n",
        "            result[key] = []\n",
        "\n",
        "        index = 0\n",
        "        for path_db in database:\n",
        "            result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "            intersectionResult = 0\n",
        "            norms1Result = 0\n",
        "            norms2Result = 0\n",
        "            bhattacharyyaResult = 0\n",
        "            for channel in range(len(cm_query_descriptors)): # 3 channels\n",
        "                for distance in range(len(cm_query_descriptors[0])): # 3 distances\n",
        "                    for angle in range(len(cm_query_descriptors[0][0])): # 4 angles\n",
        "                        intersectionResult += intersection(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "                        norms1Result += norms1(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "                        norms2Result += norms2(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "                        bhattacharyyaResult += bhattacharyya(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "            result[\"intersection\"].append((result_id, intersectionResult))\n",
        "            result[\"norms1\"].append((result_id, norms1Result))\n",
        "            result[\"norms2\"].append((result_id, norms2Result))\n",
        "            result[\"bhattacharyya\"].append((result_id, bhattacharyyaResult))\n",
        "\n",
        "            index += 1\n",
        "                \n",
        "            # writer.writerow([path + f\" ({timeList[0]})\"] + methods + [\"Time\"])\n",
        "\n",
        "            # for f in range(1, len(field)):\n",
        "            #     writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()])\n",
        "\n",
        "timestamp = time.time()\n",
        "classify_CM(query, database)\n",
        "print(f\"Time Normal: {time.time() - timestamp}\")\n",
        "\n",
        "timestamp = time.time()\n",
        "classify_CM(query_cropped, database_cropped)\n",
        "print(f\"Time Cropped: {time.time() - timestamp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par modèle binaire locaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_LBP(query, database, longueurCodes, rayon, all):\n",
        "    lbp_db_descriptors = []\n",
        "    for path_db in database:\n",
        "        row_lbp, col_lbp = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "        lbp_hist_db, _ = numpy.histogram(desc_LBP(path_db, longueurCodes, rayon), bins = range(256))\n",
        "        lbp_hist_db = lbp_hist_db / (row_lbp * col_lbp)\n",
        "        lbp_db_descriptors.append(lbp_hist_db)\n",
        "\n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        lbp_query = desc_LBP(path_query, longueurCodes, rayon)\n",
        "\n",
        "        row_lbp, col_lbp = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "        lbp_hist_query, _ = numpy.histogram(lbp_query, bins = range(256))\n",
        "        lbp_hist_query = lbp_hist_query / (row_lbp * col_lbp)\n",
        "\n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        # path = path_query.split('\\\\')[1][:-4]\n",
        "        # result_path = f\"./results/LBP/R{rayon}-P{longueurCodes}\"\n",
        "\n",
        "        # os.makedirs(result_path, exist_ok=True)\n",
        "\n",
        "        # with open(f\"{result_path}/{path}.csv\", 'w+', newline='') as file:\n",
        "            # writer = csv.writer(file)\n",
        "            # field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "        for key in methods:\n",
        "            result[key] = []\n",
        "        \n",
        "        index = 0\n",
        "        for path_db in database:\n",
        "            lbp_hist_db = lbp_db_descriptors[index]\n",
        "\n",
        "            result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "            result[\"intersection\"].append((result_id, intersection(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"norms1\"].append((result_id, norms1(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"norms2\"].append((result_id, norms2(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"bhattacharyya\"].append((result_id, bhattacharyya(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            index += 1\n",
        "\n",
        "            # writer.writerow([path + f\" ({timeList[0]})\"] + methods)\n",
        "\n",
        "            # for f in range(1, len(field)):\n",
        "            #     writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()])\n",
        "        \n",
        "        # for key in result.keys():\n",
        "        #     if key not in all:\n",
        "        #         all[key] = dict()\n",
        "        #     reverse = True if (key == \"intersection\") else False\n",
        "        #     data = [x[0] for x in sorted(result[key], key=lambda tp: tp[1], reverse=reverse)[:3]]\n",
        "        #     for d in data:\n",
        "        #         img_name = d.split(':')[0][:-6]\n",
        "        #         db_name = d.split(':')[1][:-2]\n",
        "        #         if \"strawberry\" in img_name:\n",
        "        #             if img_name not in all[key]:\n",
        "        #                 all[key][img_name] = dict()\n",
        "        #             if db_name not in all[key][img_name]:\n",
        "        #                 all[key][img_name][db_name] = 0\n",
        "        #             all[key][img_name][db_name] += 1\n",
        "        #         else:\n",
        "        #             if img_name not in all[key]:\n",
        "        #                 all[key][img_name] = (0, 0)\n",
        "        #             if img_name == db_name:\n",
        "        #                 all[key][img_name] = (all[key][img_name][0] + 1, all[key][img_name][1])\n",
        "        #             all[key][img_name] = (all[key][img_name][0], all[key][img_name][1] + 1)\n",
        "\n",
        "all = dict()\n",
        "\n",
        "timestamp = time.time()\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        classify_LBP(query, database, longueurCodes, rayon, all)\n",
        "\n",
        "print(f\"Time Normal: {time.time() - timestamp}\")\n",
        "\n",
        "timestamp = time.time()\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        classify_LBP(query_cropped, database_cropped, longueurCodes, rayon, all)\n",
        "print(f\"Time Cropped: {time.time() - timestamp}\")\n",
        "\n",
        "# print(all)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
