{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "from skimage.feature import graycomatrix\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = glob.glob(os.path.join(\"./data\", \"*.jpg\"))\n",
        "database = glob.glob(os.path.join(\"./data/database\", \"*.jpg\"))\n",
        "\n",
        "query_cropped = glob.glob(os.path.join(\"./data/cropped\", \"*.jpg\"))\n",
        "database_cropped = glob.glob(os.path.join(\"./data/cropped/database\", \"*.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def desc_cm_params(imagePath, distances = [1, 5, 10], angles = [0, numpy.pi / 2, numpy.pi, 3 * numpy.pi / 4]):\n",
        "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
        "    nb_channels = 3\n",
        "    nb_rows = len(image)\n",
        "    nb_columns = len(image[0])\n",
        "\n",
        "    three_channel_one_dimension_desc = []\n",
        "    \n",
        "    for channel in range(nb_channels):\n",
        "      one_channel_image = []\n",
        "      for row in range(nb_rows):\n",
        "        one_channel_image.append([])\n",
        "        for column in range(nb_columns):\n",
        "          one_channel_image[row].append(image[row][column][channel])\n",
        "      cm = graycomatrix(one_channel_image, distances, angles, normed=True)\n",
        "    \n",
        "      one_dimension_descriptors = []\n",
        "      for distance in range(len(cm[0][0])):\n",
        "        one_dimension_descriptors.append([])\n",
        "        for angle in range(len(cm[0][0][0])):\n",
        "            one_dimension_descriptors[distance].append([])\n",
        "            one_dim_desc = []\n",
        "            for row in range(len(cm)):\n",
        "                for col in range(len(cm[0])):\n",
        "                    one_dim_desc.append(cm[row][col][distance][angle])\n",
        "            one_dimension_descriptors[distance][angle].append(numpy.asarray(one_dim_desc, numpy.float32))\n",
        "      three_channel_one_dimension_desc.append(one_dimension_descriptors)\n",
        "\n",
        "    return three_channel_one_dimension_desc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "def desc_LBP(path, longueurCodes, rayon):\n",
        "  image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "  desc = local_binary_pattern(image, longueurCodes, rayon)\n",
        "  return numpy.asarray(desc, numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par matrice de co-occurrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_CM(query, database):\n",
        "    cm_db_descriptors = []\n",
        "    for path_db in database:\n",
        "        cm_db_descriptors.append(desc_cm_params(path_db))\n",
        "    \n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        cm_query_descriptors = desc_cm_params(path_query)\n",
        "    \n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        #path = path_query.split('\\\\')[1][:-4]\n",
        "        # with open(f\"./results/CM/{path}.csv\", 'w+', newline='') as file:\n",
        "        #     writer = csv.writer(file)\n",
        "        #     field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "        for key in methods:\n",
        "            result[key] = []\n",
        "\n",
        "        index = 0\n",
        "        for path_db in database:\n",
        "            result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "            intersectionResult = 0\n",
        "            norms1Result = 0\n",
        "            norms2Result = 0\n",
        "            bhattacharyyaResult = 0\n",
        "            for channel in range(len(cm_query_descriptors)): # 3 channels\n",
        "                for distance in range(len(cm_query_descriptors[0])): # 3 distances\n",
        "                    for angle in range(len(cm_query_descriptors[0][0])): # 4 angles\n",
        "                        intersectionResult += intersection(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "                        norms1Result += norms1(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "                        norms2Result += norms2(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "                        bhattacharyyaResult += bhattacharyya(numpy.asarray(cm_query_descriptors[channel][distance][angle]), numpy.asarray(cm_db_descriptors[index][channel][distance][angle]))\n",
        "            result[\"intersection\"].append((result_id, intersectionResult))\n",
        "            result[\"norms1\"].append((result_id, norms1Result))\n",
        "            result[\"norms2\"].append((result_id, norms2Result))\n",
        "            result[\"bhattacharyya\"].append((result_id, bhattacharyyaResult))\n",
        "\n",
        "            index += 1\n",
        "                \n",
        "            # writer.writerow([path + f\" ({timeList[0]})\"] + methods + [\"Time\"])\n",
        "\n",
        "            # for f in range(1, len(field)):\n",
        "            #     writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()])\n",
        "\n",
        "timestamp = time.time()\n",
        "classify_CM(query, database)\n",
        "print(f\"Time Normal: {time.time() - timestamp}\")\n",
        "\n",
        "timestamp = time.time()\n",
        "classify_CM(query_cropped, database_cropped)\n",
        "print(f\"Time Cropped: {time.time() - timestamp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par modèle binaire locaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_LBP(query, database, longueurCodes, rayon, all):\n",
        "    lbp_db_descriptors = []\n",
        "    for path_db in database:\n",
        "        row_lbp, col_lbp = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "        lbp_hist_db, _ = numpy.histogram(desc_LBP(path_db, longueurCodes, rayon), bins = range(256))\n",
        "        lbp_hist_db = lbp_hist_db / (row_lbp * col_lbp)\n",
        "        lbp_db_descriptors.append(lbp_hist_db)\n",
        "\n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        lbp_query = desc_LBP(path_query, longueurCodes, rayon)\n",
        "\n",
        "        row_lbp, col_lbp = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "        lbp_hist_query, _ = numpy.histogram(lbp_query, bins = range(256))\n",
        "        lbp_hist_query = lbp_hist_query / (row_lbp * col_lbp)\n",
        "\n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        # path = path_query.split('\\\\')[1][:-4]\n",
        "        # result_path = f\"./results/LBP/R{rayon}-P{longueurCodes}\"\n",
        "\n",
        "        # os.makedirs(result_path, exist_ok=True)\n",
        "\n",
        "        # with open(f\"{result_path}/{path}.csv\", 'w+', newline='') as file:\n",
        "            # writer = csv.writer(file)\n",
        "            # field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "        for key in methods:\n",
        "            result[key] = []\n",
        "        \n",
        "        index = 0\n",
        "        for path_db in database:\n",
        "            lbp_hist_db = lbp_db_descriptors[index]\n",
        "\n",
        "            result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "            result[\"intersection\"].append((result_id, intersection(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"norms1\"].append((result_id, norms1(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"norms2\"].append((result_id, norms2(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            result[\"bhattacharyya\"].append((result_id, bhattacharyya(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            index += 1\n",
        "\n",
        "            # writer.writerow([path + f\" ({timeList[0]})\"] + methods)\n",
        "\n",
        "            # for f in range(1, len(field)):\n",
        "            #     writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()])\n",
        "        \n",
        "        # for key in result.keys():\n",
        "        #     if key not in all:\n",
        "        #         all[key] = dict()\n",
        "        #     reverse = True if (key == \"intersection\") else False\n",
        "        #     data = [x[0] for x in sorted(result[key], key=lambda tp: tp[1], reverse=reverse)[:3]]\n",
        "        #     for d in data:\n",
        "        #         img_name = d.split(':')[0][:-6]\n",
        "        #         db_name = d.split(':')[1][:-2]\n",
        "        #         if \"strawberry\" in img_name:\n",
        "        #             if img_name not in all[key]:\n",
        "        #                 all[key][img_name] = dict()\n",
        "        #             if db_name not in all[key][img_name]:\n",
        "        #                 all[key][img_name][db_name] = 0\n",
        "        #             all[key][img_name][db_name] += 1\n",
        "        #         else:\n",
        "        #             if img_name not in all[key]:\n",
        "        #                 all[key][img_name] = (0, 0)\n",
        "        #             if img_name == db_name:\n",
        "        #                 all[key][img_name] = (all[key][img_name][0] + 1, all[key][img_name][1])\n",
        "        #             all[key][img_name] = (all[key][img_name][0], all[key][img_name][1] + 1)\n",
        "\n",
        "all = dict()\n",
        "\n",
        "timestamp = time.time()\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        classify_LBP(query, database, longueurCodes, rayon, all)\n",
        "\n",
        "print(f\"Time Normal: {time.time() - timestamp}\")\n",
        "\n",
        "timestamp = time.time()\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        classify_LBP(query_cropped, database_cropped, longueurCodes, rayon, all)\n",
        "print(f\"Time Cropped: {time.time() - timestamp}\")\n",
        "\n",
        "# print(all)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
