{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import urllib.request as request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "highway = glob.glob(os.path.join(\"./data/baseline/highway/input\", \"*.jpg\"))\n",
        "office = glob.glob(os.path.join(\"./data/baseline/office/input\", \"*.jpg\"))\n",
        "pedestrians = glob.glob(os.path.join(\"./data/baseline/pedestrians/input\", \"*.jpg\"))\n",
        "PETS2006 = glob.glob(os.path.join(\"./data/baseline/PETS2006/input\", \"*.jpg\"))\n",
        "\n",
        "highway_ref = glob.glob(os.path.join(\"./data/baseline/highway/groundtruth\", \"*.png\"))\n",
        "office_ref = glob.glob(os.path.join(\"./data/baseline/office/groundtruth\", \"*.png\"))\n",
        "pedestrians_ref = glob.glob(os.path.join(\"./data/baseline/pedestrians/groundtruth\", \"*.png\"))\n",
        "PETS2006_ref = glob.glob(os.path.join(\"./data/baseline/PETS2006/groundtruth\", \"*.png\"))\n",
        "\n",
        "\n",
        "# small_test_office = glob.glob(os.path.join(\"./data/baseline/small_test_office/input\", \"*.jpg\"))\n",
        "# small_test_office_ref = glob.glob(os.path.join(\"./data/baseline/small_test_office/groundtruth\", \"*.png\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_background_substrated_image(image_path, background_image):\n",
        "  threshold = 40\n",
        "  image = (cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "\n",
        "  diff = numpy.abs(image - background_image) >= threshold\n",
        "\n",
        "  int_image = diff.astype(int)\n",
        "\n",
        "  # plt.imshow(~int_image,plt.get_cmap('binary'))\n",
        "  # plt.show()\n",
        "  return int_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "COCO_NAMES = ['background']\n",
        "label_names = request.urlopen('https://raw.githubusercontent.com/gabilodeau/INF6804/master/utils/coco-labels.txt')\n",
        "for label_name in label_names.readlines():\n",
        "  COCO_NAMES.append(label_name.strip().decode('UTF-8'))\n",
        "\n",
        "def Mask_RCNN(dataset):\n",
        "  tensors = []\n",
        "  preprocess = transforms.Compose([transforms.ToTensor()])\n",
        "  THRESHOLD = 0.30\n",
        "  result = []\n",
        "  shapes = []\n",
        "  \n",
        "  for img_path in dataset:\n",
        "    img = io.imread(img_path)\n",
        "    tensors.append(preprocess(img))\n",
        "    shapes.append(img.shape)\n",
        "    \n",
        "  model = models.detection.maskrcnn_resnet50_fpn(weights='DEFAULT').eval()\n",
        "  predictions = model(tensors)\n",
        "\n",
        "  for index in range(0, len(predictions)):\n",
        "    prediction = predictions[index]\n",
        "    img_result = numpy.zeros(shapes[index][:2])\n",
        "    \n",
        "    for j, score in enumerate(prediction['scores']):\n",
        "        if score >= THRESHOLD:\n",
        "          \n",
        "          mask = prediction['masks'][j][0].detach().numpy()\n",
        "          if len(img_result) == 0:\n",
        "            img_result = numpy.array(mask)\n",
        "          else:\n",
        "            img_result = numpy.maximum(img_result, mask)\n",
        "\n",
        "    result.append(img_result)\n",
        "\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Background Substraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substract_background(dataset, background_image_index):\n",
        "    background_image = (cv2.imread(dataset[background_image_index], cv2.IMREAD_GRAYSCALE)).astype(float)\n",
        "\n",
        "    result = []\n",
        "    for path in dataset:\n",
        "        result.append(generate_background_substrated_image(path, background_image))\n",
        "    \n",
        "    return result\n",
        "\n",
        "result = substract_background(office, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparaison des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_difference(dataset, dataset_ref, show_img = False):\n",
        "    result = []\n",
        "\n",
        "    video_SI =  Mask_RCNN(dataset)\n",
        "    video_BR =  Mask_RCNN(dataset)\n",
        "\n",
        "    for img_index in range(0, len(dataset_ref)):\n",
        "        img_ref = numpy.array(cv2.imread(dataset_ref[img_index], cv2.IMREAD_GRAYSCALE).astype(float)) / 255\n",
        "        img_SI = video_SI[img_index]\n",
        "        img_BR = video_BR[img_index]\n",
        "\n",
        "        flatten = img_ref.flatten()\n",
        "        factor = (flatten[flatten != 0]).size\n",
        "        factor = 1 if (factor == 0) else factor\n",
        "        \n",
        "        result_SI = (1 - (norms1(img_SI, img_ref) / factor)) * 100\n",
        "        result_BR = (1 - (norms1(img_BR, img_ref) / factor)) * 100\n",
        "\n",
        "        if (show_img):\n",
        "            plt.imshow(img_ref); plt.axis('off'); plt.show()\n",
        "\n",
        "            plt.imshow(img_SI); plt.axis('off'); plt.show()\n",
        "            plt.imshow(numpy.abs(img_SI - img_ref)); plt.axis('off'); plt.show()\n",
        "\n",
        "            plt.imshow(img_BR); plt.axis('off'); plt.show()\n",
        "            plt.imshow(numpy.abs(img_BR - img_ref)); plt.axis('off'); plt.show()\n",
        "\n",
        "        print(f\"{img_index}: (SI:{result_SI}, BR:{result_BR})\")\n",
        "        result.append((result_SI, result_BR))\n",
        "    \n",
        "    return result\n",
        "\n",
        "classify_difference(office[0:1], office_ref[0:1], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = [highway[300:302], office[0:1], pedestrians, PETS2006]\n",
        "data_ref = [highway_ref[300:302], office_ref[0:1], pedestrians_ref, PETS2006_ref]\n",
        "data_name = [\"highway\", \"office\", \"pedestrians\", \"PETS2006\"]\n",
        "\n",
        "for data_index in range(1, len(data[0:2])):\n",
        "    current_data = data[data_index]\n",
        "    current_data_ref = data_ref[data_index]\n",
        "\n",
        "    current_result = classify_difference(current_data, current_data_ref)\n",
        "\n",
        "    with open(f\"{data_name[data_index]}.csv\", 'w+', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"index\", \"SI\", \"BR\"])\n",
        "        \n",
        "        for i in range(0, len(current_result)):\n",
        "            writer.writerow([i, current_result[i][0], current_result[i][1]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
