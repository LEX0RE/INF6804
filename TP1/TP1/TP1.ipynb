{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "from skimage.feature import graycomatrix\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inDu1K0UndIx"
      },
      "source": [
        " Matrices de Co-occurrence (MC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHuoIJ5onb2v"
      },
      "outputs": [],
      "source": [
        "def desc_CM(imagePath, distances = [1], angles = [0]):#, numpy.pi / 2, numpy.pi, 3 * numpy.pi / 4]):\n",
        "  # image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
        "  image = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n",
        "  # nbChannels = 3\n",
        "  # nbRows = len(image)\n",
        "  # nbColumns = len(image[0])\n",
        "  # oneChannelImage = []\n",
        "  # threeChannelsCoMatrix = []\n",
        "  \n",
        "  # for channel in range(nbChannels):\n",
        "  #   oneChannelImage = []\n",
        "  #   for row in range(nbRows):\n",
        "  #     oneChannelImage.append([])\n",
        "  #     for column in range(nbColumns):\n",
        "  #       oneChannelImage[row].append(image[row][column][channel])\n",
        "  #   cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "  #   threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "  \n",
        "  # for row in range(nbRows):\n",
        "  #   oneChannelImage.append([])\n",
        "  #   for column in range(nbColumns):\n",
        "  #     oneChannelImage[row].append(image[row][column])\n",
        "  #   cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "  #   threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "\n",
        "  cm = graycomatrix(image, distances, angles)\n",
        "  result = numpy.asarray(cm, numpy.float32)\n",
        "  return result\n",
        "  #return numpy.asarray(cm, numpy.float32)\n",
        "\n",
        "\n",
        "  # threeChannelsSum = []\n",
        "  # for row in range(256):\n",
        "  #   threeChannelsSum.append([])\n",
        "  #   for colum in range(256):\n",
        "  #     sum = 0\n",
        "  #     for channel in range(nbChannels):\n",
        "  #       sum += threeChannelsCoMatrix[channel][row][colum]\n",
        "  #     threeChannelsSum[row].append(sum)\n",
        "\n",
        "  # return threeChannelsSum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Co-Occurrence Matrix in Grayscale "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def desc_grayscale_CM(imagePath, distances = [1], angles = [0]):#, numpy.pi / 2, numpy.pi, 3 * numpy.pi / 4]):\n",
        "    image = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n",
        "    cm = graycomatrix(image, distances, angles, normed=True)\n",
        "\n",
        "    # Make the cm descriptor into a 1 dimension array\n",
        "    co_matrix = []\n",
        "    for row in range(len(cm)):\n",
        "        for col in range(len(cm[0])):\n",
        "            co_matrix.append(cm[row][col][0][0])\n",
        "\n",
        "    return numpy.asarray(co_matrix, numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Co-Occurence Matrix in Color For Each Channel (probablement à delete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def desc_color_CM(imagePath, distances = [1], angles = [0]):\n",
        "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
        "    nbChannels = 3\n",
        "    nbRows = len(image)\n",
        "    nbColumns = len(image[0])\n",
        "    oneChannelImage = []\n",
        "    threeChannelsCoMatrix = []\n",
        "    \n",
        "    for channel in range(nbChannels):\n",
        "      oneChannelImage = []\n",
        "      for row in range(nbRows):\n",
        "        oneChannelImage.append([])\n",
        "        for column in range(nbColumns):\n",
        "          oneChannelImage[row].append(image[row][column][channel])\n",
        "      cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "      threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "    \n",
        "    for row in range(nbRows):\n",
        "      oneChannelImage.append([])\n",
        "      for column in range(nbColumns):\n",
        "        oneChannelImage[row].append(image[row][column])\n",
        "      cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "      threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Modèles Binaires Locaux (LBP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "def desc_LBP(path, longueurCodes, rayon):\n",
        "  image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "  desc = local_binary_pattern(image, longueurCodes, rayon)\n",
        "  return numpy.asarray(desc, numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = glob.glob(os.path.join(\"./data\", \"*.jpg\"))\n",
        "database = glob.glob(os.path.join(\"./data/database\", \"*.jpg\"))\n",
        "\n",
        "query_cropped = glob.glob(os.path.join(\"./data/cropped\", \"*.jpg\"))\n",
        "database_cropped = glob.glob(os.path.join(\"./data/cropped/database\", \"*.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))\n",
        "\n",
        "def MDPA(vector_i, vector_j):\n",
        "    sum_m = 0\n",
        "    diff = vector_i - vector_j\n",
        "    for m in range(len(vector_i)):\n",
        "        sum_m += abs(numpy.sum(diff[:m]))\n",
        "    return sum_m\n",
        "\n",
        "def cosineSimilarity(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.multiply(vector_i, vector_j)) / (numpy.sqrt(numpy.sum(vector_i)) * numpy.sqrt(numpy.sum(vector_j)))\n",
        "\n",
        "def hammingDistance(vector_i, vector_j):\n",
        "    return numpy.sum(vector_i == vector_j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par matrice de co-occurrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_MC(query, database):\n",
        "    timeList = []\n",
        "    \n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        timestamp = time.time_ns()\n",
        "        cm_query = desc_grayscale_CM(path_query)\n",
        "        timeList.append(time.time_ns() - timestamp)\n",
        "    \n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\", \"MDPA\", \"cosineSimilarity\", \"hammingDistance\"]\n",
        "\n",
        "        path = path_query.split('\\\\')[1][:-4]\n",
        "        with open(f\"./results/MC/{path}.csv\", 'w+', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "            for key in methods:\n",
        "                result[key] = []\n",
        "\n",
        "            for path_db in database:\n",
        "                timestamp = time.time_ns()\n",
        "                cm_db = desc_grayscale_CM(path_db)\n",
        "                timeList.append(time.time_ns() - timestamp)\n",
        "                result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "                result[\"intersection\"].append((result_id, intersection(cm_query, cm_db)))\n",
        "                result[\"norms1\"].append((result_id, norms1(cm_query, cm_db)))\n",
        "                result[\"norms2\"].append((result_id, norms2(cm_query, cm_db)))\n",
        "                result[\"bhattacharyya\"].append((result_id, bhattacharyya(cm_query, cm_db)))\n",
        "                result[\"MDPA\"].append((result_id, MDPA(cm_query, cm_db)))\n",
        "                result[\"cosineSimilarity\"].append((result_id, cosineSimilarity(cm_query, cm_db)))\n",
        "                result[\"hammingDistance\"].append((result_id, hammingDistance(cm_query, cm_db)))\n",
        "                \n",
        "            writer.writerow([path + f\" ({timeList[0]})\"] + methods + [\"Time\"])\n",
        "\n",
        "            for f in range(1, len(field)):\n",
        "                writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()] + [timeList[f]])\n",
        "\n",
        "        break\n",
        "\n",
        "classify_MC(query, database)\n",
        "classify_MC(query_cropped, database_cropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par modèle binaire locaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_LBP(query, database, longueurCodes, rayon):\n",
        "    timeList = []\n",
        "\n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        timestamp = time.time_ns()\n",
        "        lbp_query = desc_LBP(path_query, longueurCodes, rayon)\n",
        "        timeList.append(time.time_ns() - timestamp)\n",
        "\n",
        "        row_lbp, col_lbp = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "        lbp_hist_query, _ = numpy.histogram(lbp_query, bins = range(256))\n",
        "        lbp_hist_query = lbp_hist_query / (row_lbp * col_lbp)\n",
        "\n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\", \"MDPA\", \"cosineSimilarity\", \"hammingDistance\"]\n",
        "\n",
        "        path = path_query.split('\\\\')[1][:-4]\n",
        "        result_path = f\"./results/LBP/R{rayon}-L{longueurCodes}\"\n",
        "\n",
        "        os.makedirs(result_path, exist_ok=True)\n",
        "\n",
        "        with open(f\"{result_path}/{path}.csv\", 'w+', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "            for key in methods:\n",
        "                result[key] = []\n",
        "\n",
        "            for path_db in database:\n",
        "                timestamp = time.time_ns()\n",
        "                lbp_db = desc_LBP(path_db, longueurCodes, rayon)\n",
        "                timeList.append(time.time_ns() - timestamp)\n",
        "                \n",
        "                row_lbp, col_lbp = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "                lbp_hist_db, _ = numpy.histogram(lbp_db, bins = range(256))\n",
        "                lbp_hist_db = lbp_hist_db / (row_lbp * col_lbp)\n",
        "\n",
        "                result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "                result[\"intersection\"].append((result_id, intersection(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"norms1\"].append((result_id, norms1(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"norms2\"].append((result_id, norms2(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"bhattacharyya\"].append((result_id, bhattacharyya(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"MDPA\"].append((result_id, MDPA(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"cosineSimilarity\"].append((result_id, cosineSimilarity(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"hammingDistance\"].append((result_id, hammingDistance(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            writer.writerow([path + f\" ({timeList[0]})\"] + methods + [\"Time\"])\n",
        "\n",
        "            for f in range(1, len(field)):\n",
        "                writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()] + [timeList[f]])\n",
        "\n",
        "for rayon in range(1, 5):\n",
        "    for longueurCodes in range(3, 10):\n",
        "        classify_LBP(query, database, longueurCodes, rayon)\n",
        "        classify_LBP(query_cropped, database_cropped, longueurCodes, rayon)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
