{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "from skimage.feature import graycomatrix\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inDu1K0UndIx"
      },
      "source": [
        " Matrices de Co-occurrence (MC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHuoIJ5onb2v"
      },
      "outputs": [],
      "source": [
        "def desc_CM(imagePath, distances = [1], angles = [0]):#, numpy.pi / 2, numpy.pi, 3 * numpy.pi / 4]):\n",
        "  # image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
        "  image = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n",
        "  # nbChannels = 3\n",
        "  # nbRows = len(image)\n",
        "  # nbColumns = len(image[0])\n",
        "  # oneChannelImage = []\n",
        "  # threeChannelsCoMatrix = []\n",
        "  \n",
        "  # for channel in range(nbChannels):\n",
        "  #   oneChannelImage = []\n",
        "  #   for row in range(nbRows):\n",
        "  #     oneChannelImage.append([])\n",
        "  #     for column in range(nbColumns):\n",
        "  #       oneChannelImage[row].append(image[row][column][channel])\n",
        "  #   cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "  #   threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "  \n",
        "  # for row in range(nbRows):\n",
        "  #   oneChannelImage.append([])\n",
        "  #   for column in range(nbColumns):\n",
        "  #     oneChannelImage[row].append(image[row][column])\n",
        "  #   cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "  #   threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "\n",
        "  cm = graycomatrix(image, distances, angles)\n",
        "  result = numpy.asarray(cm, numpy.float32)\n",
        "  return result\n",
        "  #return numpy.asarray(cm, numpy.float32)\n",
        "\n",
        "\n",
        "  # threeChannelsSum = []\n",
        "  # for row in range(256):\n",
        "  #   threeChannelsSum.append([])\n",
        "  #   for colum in range(256):\n",
        "  #     sum = 0\n",
        "  #     for channel in range(nbChannels):\n",
        "  #       sum += threeChannelsCoMatrix[channel][row][colum]\n",
        "  #     threeChannelsSum[row].append(sum)\n",
        "\n",
        "  # return threeChannelsSum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Co-Occurrence Matrix in Grayscale "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def desc_grayscale_CM(imagePath, distances = [1], angles = [0]):#, numpy.pi / 2, numpy.pi, 3 * numpy.pi / 4]):\n",
        "    image = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE)\n",
        "    cm = graycomatrix(image, distances, angles, normed=True)\n",
        "\n",
        "    # Make the cm descriptor into a 1 dimension array\n",
        "    co_matrix = []\n",
        "    for row in range(len(cm)):\n",
        "        for col in range(len(cm[0])):\n",
        "            co_matrix.append(cm[row][col][0][0])\n",
        "\n",
        "    return numpy.asarray(co_matrix, numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Co-Occurence Matrix in Color For Each Channel (probablement à delete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def desc_color_CM(imagePath, distances = [1], angles = [0]):\n",
        "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
        "    nbChannels = 3\n",
        "    nbRows = len(image)\n",
        "    nbColumns = len(image[0])\n",
        "    oneChannelImage = []\n",
        "    threeChannelsCoMatrix = []\n",
        "    \n",
        "    for channel in range(nbChannels):\n",
        "      oneChannelImage = []\n",
        "      for row in range(nbRows):\n",
        "        oneChannelImage.append([])\n",
        "        for column in range(nbColumns):\n",
        "          oneChannelImage[row].append(image[row][column][channel])\n",
        "      cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "      threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "    \n",
        "    for row in range(nbRows):\n",
        "      oneChannelImage.append([])\n",
        "      for column in range(nbColumns):\n",
        "        oneChannelImage[row].append(image[row][column])\n",
        "      cm = graycomatrix(oneChannelImage, distances, angles)\n",
        "      threeChannelsCoMatrix.append(numpy.asarray(cm, numpy.float32))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Modèles Binaires Locaux (LBP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "def desc_LBP(path, longueurCodes, rayon):\n",
        "  image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "  desc = local_binary_pattern(image, longueurCodes, rayon)\n",
        "  return numpy.asarray(desc, numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = glob.glob(os.path.join(\"./data\", \"*.jpg\"))\n",
        "database = glob.glob(os.path.join(\"./data/database\", \"*.jpg\"))\n",
        "\n",
        "query_cropped = glob.glob(os.path.join(\"./data/cropped\", \"*.jpg\"))\n",
        "database_cropped = glob.glob(os.path.join(\"./data/cropped/database\", \"*.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par matrice de co-occurrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_MC(query, database):\n",
        "    timeList = []\n",
        "    \n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        timestamp = time.time_ns()\n",
        "        cm_query = desc_grayscale_CM(path_query)\n",
        "        timeList.append(time.time_ns() - timestamp)\n",
        "    \n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        path = path_query.split('\\\\')[1][:-4]\n",
        "        with open(f\"./results/MC/{path}.csv\", 'w+', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "            for key in methods:\n",
        "                result[key] = []\n",
        "\n",
        "            for path_db in database:\n",
        "                timestamp = time.time_ns()\n",
        "                cm_db = desc_grayscale_CM(path_db)\n",
        "                timeList.append(time.time_ns() - timestamp)\n",
        "                result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "                result[\"intersection\"].append((result_id, intersection(cm_query, cm_db)))\n",
        "                result[\"norms1\"].append((result_id, norms1(cm_query, cm_db)))\n",
        "                result[\"norms2\"].append((result_id, norms2(cm_query, cm_db)))\n",
        "                result[\"bhattacharyya\"].append((result_id, bhattacharyya(cm_query, cm_db)))\n",
        "                \n",
        "            writer.writerow([path + f\" ({timeList[0]})\"] + methods + [\"Time\"])\n",
        "\n",
        "            for f in range(1, len(field)):\n",
        "                writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()] + [timeList[f]])\n",
        "\n",
        "        break\n",
        "\n",
        "classify_MC(query, database)\n",
        "classify_MC(query_cropped, database_cropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification par modèle binaire locaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time Normal R1-P4: 54928927600\n",
            "Time Cropped R1-P4: 21719798500\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[81], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m longueurCodes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m     55\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mclassify_LBP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongueurCodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrayon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime Normal R\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrayon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-P\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlongueurCodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime_ns()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n",
            "Cell \u001b[1;32mIn[81], line 32\u001b[0m, in \u001b[0;36mclassify_LBP\u001b[1;34m(query, database, longueurCodes, rayon)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path_db \u001b[38;5;129;01min\u001b[39;00m database:\n\u001b[0;32m     31\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[1;32m---> 32\u001b[0m     lbp_db \u001b[38;5;241m=\u001b[39m \u001b[43mdesc_LBP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongueurCodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrayon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     row_lbp, col_lbp \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path_db, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     36\u001b[0m     lbp_hist_db, _ \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mhistogram(lbp_db, bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m256\u001b[39m))\n",
            "Cell \u001b[1;32mIn[69], line 3\u001b[0m, in \u001b[0;36mdesc_LBP\u001b[1;34m(path, longueurCodes, rayon)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdesc_LBP\u001b[39m(path, longueurCodes, rayon):\n\u001b[0;32m      2\u001b[0m   image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m----> 3\u001b[0m   desc \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_binary_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongueurCodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrayon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39masarray(desc, numpy\u001b[38;5;241m.\u001b[39mfloat32)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\skimage\\feature\\texture.py:359\u001b[0m, in \u001b[0;36mlocal_binary_pattern\u001b[1;34m(image, P, R, method)\u001b[0m\n\u001b[0;32m    353\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying `local_binary_pattern` to floating-point images may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive unexpected results when small numerical differences between \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjacent pixels are present. It is recommended to use this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction with images of integer dtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    358\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(image, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m--> 359\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_local_binary_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def classify_LBP(query, database, longueurCodes, rayon):\n",
        "    timeList = []\n",
        "\n",
        "    for path_query in query:\n",
        "        result = dict()\n",
        "\n",
        "        timestamp = time.time_ns()\n",
        "        lbp_query = desc_LBP(path_query, longueurCodes, rayon)\n",
        "        timeList.append(time.time_ns() - timestamp)\n",
        "\n",
        "        row_lbp, col_lbp = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "        lbp_hist_query, _ = numpy.histogram(lbp_query, bins = range(256))\n",
        "        lbp_hist_query = lbp_hist_query / (row_lbp * col_lbp)\n",
        "\n",
        "        methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\"]\n",
        "\n",
        "        path = path_query.split('\\\\')[1][:-4]\n",
        "        result_path = f\"./results/LBP/R{rayon}-P{longueurCodes}\"\n",
        "\n",
        "        os.makedirs(result_path, exist_ok=True)\n",
        "\n",
        "        with open(f\"{result_path}/{path}.csv\", 'w+', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            field = [path] + [x.split('\\\\')[1][:-4] for x in database]\n",
        "            \n",
        "            for key in methods:\n",
        "                result[key] = []\n",
        "\n",
        "            for path_db in database:\n",
        "                timestamp = time.time_ns()\n",
        "                lbp_db = desc_LBP(path_db, longueurCodes, rayon)\n",
        "                \n",
        "                row_lbp, col_lbp = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "                lbp_hist_db, _ = numpy.histogram(lbp_db, bins = range(256))\n",
        "                lbp_hist_db = lbp_hist_db / (row_lbp * col_lbp)\n",
        "\n",
        "                result_id = path_query.split('\\\\')[1][:-4] + \":\" + path_db.split('\\\\')[1][:-4]\n",
        "\n",
        "                result[\"intersection\"].append((result_id, intersection(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"norms1\"].append((result_id, norms1(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"norms2\"].append((result_id, norms2(lbp_hist_query, lbp_hist_db)))\n",
        "                result[\"bhattacharyya\"].append((result_id, bhattacharyya(lbp_hist_query, lbp_hist_db)))\n",
        "                \n",
        "                timeList.append(time.time_ns() - timestamp)\n",
        "\n",
        "            writer.writerow([path + f\" ({timeList[0]})\"] + methods + [\"Time\"])\n",
        "\n",
        "            for f in range(1, len(field)):\n",
        "                writer.writerow([field[f]] + [result[key][f - 1][1] for key in result.keys()] + [timeList[f]])\n",
        "\n",
        "for rayon in range(1, 6, 2):\n",
        "    for longueurCodes in range(4, 25, 4):\n",
        "        timestamp = time.time()\n",
        "        classify_LBP(query, database, longueurCodes, rayon)\n",
        "        print(f\"Time Normal R{rayon}-P{longueurCodes}: {time.time() - timestamp}\")\n",
        "        timestamp = time.time()\n",
        "        classify_LBP(query_cropped, database_cropped, longueurCodes, rayon)\n",
        "        print(f\"Time Cropped R{rayon}-P{longueurCodes}: {time.time() - timestamp}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
