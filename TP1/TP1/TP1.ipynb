{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWx4lZbjojK"
      },
      "source": [
        "INF8770 Technologies multimédias\n",
        "\n",
        "Polytechnique Montréal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IVgLQR6k7e1"
      },
      "source": [
        "Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GJVo3C46kfjR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from skimage.feature.texture import local_binary_pattern\n",
        "import glob\n",
        "import cv2\n",
        "import numpy\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inDu1K0UndIx"
      },
      "source": [
        " Matrices de Co-occurrence (MC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHuoIJ5onb2v"
      },
      "outputs": [],
      "source": [
        "def desc_MC(imagePath, dx, dy, color1, color2):\n",
        "  image = Image.open(imagePath)\n",
        "  width = len(image)\n",
        "  height = len(image[0])\n",
        "  result = []\n",
        "\n",
        "  for column in range(0, width):\n",
        "    if column + dx >= width:\n",
        "      break\n",
        "    for row in range(0, height):\n",
        "      if row + dy >= height: \n",
        "        break\n",
        "      areCorrespondingColors = True\n",
        "      for canal in range(0, 3):\n",
        "        if image[column][row][canal] != color1[canal] or image[column + dx][row + dy][canal] != color2[canal]:\n",
        "           areCorrespondingColors = False\n",
        "           break\n",
        "      result += 1 if areCorrespondingColors else 0\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo6N_r5snjUB"
      },
      "source": [
        "Modèles Binaires Locaux (LBP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3ebnD69ncvx"
      },
      "outputs": [],
      "source": [
        "longueurCodes = 8\n",
        "rayon = 1\n",
        "\n",
        "def desc_LBP(path):\n",
        "  image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
        "  desc =  local_binary_pattern(image, longueurCodes, rayon)\n",
        "  return numpy.asarray(desc, numpy.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = glob.glob(os.path.join(\"./data\", \"*.jpg\"))\n",
        "database = glob.glob(os.path.join(\"./data/database\", \"*.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Méthode de comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intersection(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.minimum(vector_i, vector_j)) / numpy.sum(vector_j)\n",
        "\n",
        "def norms1(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.abs(vector_i - vector_j))\n",
        "\n",
        "def norms2(vector_i, vector_j):\n",
        "    return numpy.sqrt(numpy.sum(numpy.power(vector_i - vector_j, 2)))\n",
        "\n",
        "def bhattacharyya(vector_i, vector_j):\n",
        "    return -numpy.log((numpy.sum(numpy.sqrt(numpy.multiply(vector_i, vector_j)))))\n",
        "\n",
        "def MDPA(vector_i, vector_j):\n",
        "    sum_m = 0\n",
        "    for m in range(len(vector_i)):\n",
        "        sum_n = 0\n",
        "        for n in range(m):\n",
        "            sum_n += vector_i[n] - vector_j[n]\n",
        "        sum_m += abs(sum_n)\n",
        "\n",
        "    return sum_m\n",
        "\n",
        "def cosineSimilarity(vector_i, vector_j):\n",
        "    return numpy.sum(numpy.multiply(vector_i, vector_j)) / (numpy.sqrt(numpy.sum(vector_i)) * numpy.sqrt(numpy.sum(vector_j)))\n",
        "\n",
        "def hammingDistance(vector_i, vector_j):\n",
        "    sum = 0\n",
        "    for k in range(len(vector_i)):\n",
        "        sum += 1 if (vector_i[k] == vector_j[k]) else 0 \n",
        "\n",
        "    return sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modification des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "intersection [('airplane_query:airplane_4', 0.9285349455986982), ('airplane_query:airplane_3', 0.9098495553384187), ('airplane_query:airplane_1', 0.9074429863434066)]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "can only concatenate list (not \"tuple\") to list",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m         reverse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m (key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintersection\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhammingDistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28mprint\u001b[39m(key, \u001b[38;5;28msorted\u001b[39m(result_lbp[key], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m tp: tp[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39mreverse)[:\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m---> 69\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow(\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresult_lbp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# TODO Faire les carrés englobants\n",
        "\n",
        "for path_query in query:\n",
        "    result_mc = dict()\n",
        "    result_lbp = dict()\n",
        "\n",
        "    #mc_query = desc_MC()\n",
        "    lbp_query = desc_LBP(path_query)\n",
        "\n",
        "    #row_mc, col_mc = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "    row_lbp, col_lbp = cv2.imread(path_query, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "    #mc_hist_query, bins = numpy.histogram(mc_query, bins = range(256))\n",
        "    lbp_hist_query, bins = numpy.histogram(lbp_query, bins = range(256))\n",
        "\n",
        "    #mc_hist_query = mc_hist_query / (row_mc * col_mc)\n",
        "    lbp_hist_query = lbp_hist_query / (row_lbp * col_lbp)\n",
        "\n",
        "    methods = [\"intersection\", \"norms1\", \"norms2\", \"bhattacharyya\", \"MDPA\", \"cosineSimilarity\", \"hammingDistance\"]\n",
        "\n",
        "    with open(f\"./results/{path_query[7:-4]}.csv\", 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        field = [\"\"] + [x[16:-4] for x in database]\n",
        "        writer.writerow(field)\n",
        "        \n",
        "        for key in methods:\n",
        "            #result_mc[key] = []\n",
        "            result_lbp[key] = []\n",
        "\n",
        "        for path_db in database:\n",
        "            # mc_db = desc_MC()\n",
        "            lbp_db = desc_LBP(path_db)\n",
        "            \n",
        "            #row_mc, col_mc = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "            row_lbp, col_lbp = cv2.imread(path_db, cv2.IMREAD_GRAYSCALE).shape\n",
        "\n",
        "            #mc_hist_db, bins = numpy.histogram(mc_db, bins = range(256))\n",
        "            lbp_hist_db, bins = numpy.histogram(lbp_db, bins = range(256))\n",
        "\n",
        "            #mc_hist_db = mc_hist_db / (row_mc * col_mc)\n",
        "            lbp_hist_db = lbp_hist_db / (row_lbp * col_lbp)\n",
        "\n",
        "            result_id = path_query[7:-4] + \":\" + path_db[16:-4]\n",
        "\n",
        "            #result_mc[\"intersection\"].append((result_id, intersection(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"intersection\"].append((result_id, intersection(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            #result_mc[\"norms1\"].append((result_id, norms1(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"norms1\"].append((result_id, norms1(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            #result_mc[\"norms2\"].append((result_id, norms2(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"norms2\"].append((result_id, norms2(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            #result_mc[\"bhattacharyya\"].append((result_id, bhattacharyya(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"bhattacharyya\"].append((result_id, bhattacharyya(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            #result_mc[\"MDPA\"].append((result_id, MDPA(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"MDPA\"].append((result_id, MDPA(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            #result_mc[\"cosineSimilarity\"].append((result_id, cosineSimilarity(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"cosineSimilarity\"].append((result_id, cosineSimilarity(lbp_hist_query, lbp_hist_db)))\n",
        "\n",
        "            #result_mc[\"hammingDistance\"].append((result_id, hammingDistance(mc_hist_query, mc_hist_db)))\n",
        "            result_lbp[\"hammingDistance\"].append((result_id, hammingDistance(lbp_hist_query, lbp_hist_db)))\n",
        "            \n",
        "        for key in result_lbp.keys():\n",
        "            reverse = True if (key in [\"intersection\", \"hammingDistance\"]) else False\n",
        "            print(key, sorted(result_lbp[key], key=lambda tp: tp[1], reverse=reverse)[:3])\n",
        "            writer.writerow([key] + [result_lbp[key][1]])\n",
        "    break\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
